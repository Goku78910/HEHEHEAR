import pandas as pd
import numpy as np
from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
# Step 1: Generate synthetic dataset
X, _ = make_blobs(n_samples=100, centers=3, n_features=3,
random_state=42)
df = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3'])
# Step 2: Preprocess (scale) the data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df)
df_scaled = pd.DataFrame(scaled_features, columns=df.columns)
# Step 3: Apply K-Means clustering
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
kmeans.fit(df_scaled)
# Step 4: Add cluster labels
df['Cluster'] = kmeans.labels_
# Step 5: Print number of data points in each cluster
print("\033[95mNumber of data points in each cluster:\033[0m")
print(df['Cluster'].value_counts())
# Step 6: Print cluster centroids
print("\n\033[95mCluster centroids:\033[0m")
centroids = pd.DataFrame(kmeans.cluster_centers_, columns=df.columns[:-1])
print(centroids)
# Step 7: Print mean values of features across clusters
print("\n\033[95mMean values of features across clusters:\033[0m")
cluster_means = df.groupby('Cluster').mean(numeric_only=True)
print(cluster_means)